\chapter{Trabalhos Relacionados}
Os impactos do fenômeno ENSO vêm sendo estudados extensamente em diversas áreas. Segundo \citeonline{Cirino2015}, eventos
de El Niño e La Niña influenciam significativamente a agricultura brasileira, especialmente nas regiões Sul e Nordeste.

Um estudo de \citeonline{Pirani2024} demonstrou que a ocorrência do fenômeno El Niño está associada a uma maior taxa de 
casos de dengue no estado de São Paulo, devido a um aumento na temperatura e precipitação, condições
favoráveis para a proliferação do mosquito Aedes aegypti.

Segundo \citeonline{Capozzoli2017}, o fenômeno ENSO tem uma relação direta sobre a disponibilidade de recursos hídricos
nas bacias hidrográficas brasileiras, o que sugere um impacto direto sobre a geração hidrelétrica no Brasil. Além disso,
os resultados são coerentes com a literatura, indicando impactos distintos nas diferentes regiões do país.

Naturalmente, o fenômeno ENSO também vem sendo estudado no contexto do setor elétrico brasileiro. Segundo um
estudo da \citeonline{epe2023}, a ocorrência do fenômeno La Niña em 2021 foi um fator determinante para a crise hídrica
que afetou o Brasil nesse período, em decorrência da redução das afluências, ou seja, a quantidade de água que chega aos
reservatórios das usinas hidrelétricas.

De acordo com \citeonline{Sanchez2006}, o recurso associado à fonte eólica é diretamente afetado por variáveis climáticas,
como densidade local do ar, precipitação, temperatura e cobertura de nuvens. Nesse sentido, o trabalho apresenta um sistema de 
previsão estatística para a produção de energia eólica de curto prazo, destacando a necessidade de adaptabilidade 
para lidar com as relações não lineares entre as variáveis climáticas e a geração eólica.

Segundo o relatório da Comissão Permanente para Análise de Metodologias e Programas Computacionais do Setor Elétrico (CPAMP),
constituída por instituições do setor elétrico como EPE, ONS e CEPEL, a incorporação de dados de variáveis climáticas,
como o fenômeno ENSO, aos modelos computacionais é ativamente discutida devido a relação entre as séries históricas de 
vazões e dos ciclos de índices climáticos. \cite{cpamp2019}

De acordo com \citeonline{Resende2018}, o uso de modelos de aprendizado de máquina para previsão de carga do SIN tem o
potencial de aprimorar o resultado das previsões, reduzindo os desvios de previsão de carga e, consequentemente, uma redução 
significativa dos custos de operação do sistema elétrico. Infere-se, portanto, que essa abordagem também poderia
ser aplicada para estimar outros parâmetros, como a geração futura.

Para isso, é essencial selecionar modelos que sejam capazes de capturar as relações potencialmente complexas entre os
dados de geração e os fenômenos climáticos. Considerando que a literatura sugere que essa relação seja altamente não-linear,
modelos neurais seriam uma escolha natural, mas não necessariamente os modelos neurais mais avançados seriam os mais adequados.

Segundo \citeonline{Zeng2022}, modelos de previsão de séries temporais baseados na arquitetura \textit{Transformer}, introduzida 
por \citeonline{Vaswani2017}, podem produzir resultados inferiores quando comparados a modelos mais simples. Nesse contexto,
surge então a arquitetura \textit{TSMixer}, proposta por \citeonline{Chen2023}. Essa arquitetura, embora mais simples, produz resultados 
consideravelmente superiores com uma fração do custo computacional. 


% ----------------------------------------------------------------------------------------------------------------------
\chapter{Fundamentação Teórica}
\section{Impacto do ENSO na Geração de Energia Elétrica}
O ENSO é um fenômeno que ocorre no Oceano Pacífico Equatorial, caracterizado por variações na temperatura da superfície
do mar (TSM) em regiões específicas, como ilustrado na Figura \ref{fig:regioes_enso}. O fenômeno é um dos principais fatores 
que influenciam os padrões de vento e precipitação em diversas regiões da América do Sul e seus efeitos se estendem por 
todas as regiões do Brasil. \cite{Andreoli2016}

\begin{figure}[!ht]
	\IBGEtab{\caption{Regiões do fenômeno El Niño-Oscilação Sul (ENSO)}
			 \label{fig:regioes_enso}}
	{\includesvg[scale=1]{figuras/regioes_enso_global}}
	{\fonte{o autor.}}
\end{figure}

Os impactos em cada região estão resumidos a seguir, de acordo com \citeonline{Capozzoli2017}:
\begin{itemize}
	\item \textbf{Sul:} a região Sul é uma das mais consistentemente afetadas. Eventos de El Niño tendem a causar precipitação acima da média,
particularmente durante a primavera e o verão, enquanto eventos de La Niña estão associados à condições de seca.
	\item \textbf{Sudeste:} a região Sudeste apresenta uma resposta mais complexa, sendo consdierada uma zona de transição. A bacia do Rio Paraná,
em especial, apresenta sensibilidade aos fenômenos do ENSO, tendo apresentado tendência de aumento de vazão durante alguns
eventos de El Niño.
	\item \textbf{Norte/Nordeste:} para as regiões Norte e Nordeste, eventos de El Niño estão associados a períodos de seca, enquanto eventos de
La Niña tendem a trazer chuvas acima da média. No entanto, é importante destacar que outros fenômenos atmosféricos podem
interferir com esses padrões, modulando os efeitos do ENSO.
\end{itemize}

Sendo assim, verifica-se que as variações induzidas pelos fenômenos do ENSO traduzem-se diretamente em variações nas
vazões dos rios que alimentam as bacias, que por sua vez impactam o potencial de geração da fonte hidráulica.


% ----------------------------------------------------------------------------------------------------------------------
\section{O Modelo NEWAVE}
\label{sec:newave}

Desenvolvido e mantido pelo Centro de Pesquisas de Energia Elétrica (CEPEL) e amplamente utilizado pelo setor elétrico 
brasileiro para definição de estratégias e tomada de decisão, o NEWAVE é um modelo de otimização que busca minimizar os 
custos de operação do sistema, considerando a incerteza das afluências futuras e a operação de um sistema 
hidro-térmico-eólico interligado. O modelo é utilizado para estudos como:
\begin{itemize}
	\item Elaboração do Plano Decenal de Expansão de Energia (PDE), pela EPE;
	\item Elaboração do Programa Mensal de Operação (PMO) e Plano de Operação Energética (PEN), pelo ONS;
	\item Formação de preços, como no cálculo do Preço de Liquidação das Diferenças (PLD) pelo CCEE;
	\item Cálculo de Garantia Física e da Energia Assegurada para empreendimentos de geração participantes nos leilões 
    de energia elétrica, pela EPE;
	\item Elaboração de diretrizes para os leilões de energia, pela EPE.
\end{itemize}

Em resumo, o modelo emprega a Programação Dinâmica Dual Estocástica (PDDE), uma técnica de otimização que permite lidar 
com as incertezas ligadas às afluências futuras sem que o modelo se torne computacionalmente impraticável, considerando 
múltiplos reservatórios, interconexões e o horizonte temporal de médio e longo prazos.

\subsection{Representação das Usinas}
O NEWAVE modela o sistema de geração hidrelétrico em Reservatórios Equivalentes de Energia (REEs), que são grupos de
usinas associadas a um subsistema ou submercado de energia. Cada subsistema pode conter mais de um REE, possibilitando
diferenciar bacias hidrográficas com regimes distintos, ainda que pertençam a um mesmo subsistema. 

Além disso, cada REE é definido por um conjunto de parâmetros que são calculados a partir das características indivuduais 
de cada usina. Nas versões mais recentes do modelo, também é possível considerar todas as usinas indivudalmente ou operar
de maneira híbrtida, ou seja, considerando alguns REEs e outras usinas individualmente.

As usinas termelétricas são representadas no modelo através de classes térmicas. Cada classe agrupa usinas com custos 
semelhantes e está associada a um subsistema. Cada classe também é definida por um conjunto de parâmetros calculados
a partir das características individuais de cada usina.

Nas versões mais recentes do modelo, a fonte eólica também é modelada. De maneira similar, os parques eólicos são agrupados
em Parques Eólicos Equivalentes (PEE). O agrupamento é feito a aprtir de dados de cadastro de cada prque eólico, estado,
submercado, função de produção (curva relacionando a velocidade do vento com a potência gerada), dados sobre torres de
medição e séries históricas de velocidade do vento.

\subsection{Dados de Entrada}
O modelo requer um conjunto de dados de entrada que inclui as características das usinas, dados dos subsistemas, demanda,
séries históricas de vazões e ventos, cronogramas de expansão, restrições operativas, dentre outros. Observa-se
que todos os dados de entrada são locais e, portanto, o modelo não considera variáveis externas, como fenomênos climáticos
como o EN e LN, que podem impactar a geração de energia elétrica. 

Ainda que as últimas versões do modelo apresentem campos previstos para a entrada de dados do ENSO, esses campos
estão marcados como "não implementados". Dessa forma, entende-se que o modelo não considera diretamente o impacto 
dessas variáveis. No entanto, vale destacar que essas variáveis externas podem ser utilizadas para elaborar as séries históricas de 
vazões e velocidade de ventos utilizadas como dados de entrada. 


% ----------------------------------------------------------------------------------------------------------------------
\newpage
\section{Modelos Linear e Não-linear}
Nesse projeto, foram utilizados modelos de regressão linear e não linear a fim de se obter uma \textit{baseline} para
comparação com o modelo neural. Para ambos os casos, a biblioteca \textit{scikit-learn} foi utilizada, uma biblioteca
que contém diversos algoritmos para análise de dados, incluindo modelos de classificação e regressão. A biblioteca
é construída utilizando as bibliotecas \textit{NumPy} e \textit{SciPy}, que fornecem suporte para operações
matemáticas e científicas, amplamente utilizadas na comunidade de ciência de dados e aprendizado de máquina.

\subsection{Modelo Linear}
O modelo linear utilizado foi o \textit{LinearRegression} da biblioteca \textit{scikit-learn}. Ele consiste na
aplicação do método dos mínimos quadrados para determinar os coeficientes da equação linear que melhor se ajusta aos dados,
conforme ilustrado na Figura \ref{fig:modelo_linear}.
\begin{figure}[!ht]
	\IBGEtab{\caption{Regressão linear de uma senoide}
			 \label{fig:modelo_linear}}
	{\includesvg[scale=1]{figuras/modelo_linear_exemplo}}
	{\fonte{o autor.}}
\end{figure}

Naturalmente, esse tipo de modelo é utilizado quando se espera que a variável de interesse (dependente) seja uma combinação linear
das variáveis de entrada (independentes), conforme a equação \ref{eq:regressao_linear},
\begin{equation}
\label{eq:regressao_linear}
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n
\end{equation}
em que $y$ é a variável de interesse, 
$\beta_0$ é o intercepto, $\beta_1, \beta_2, ..., \beta_n$ são os coeficientes e $x_1, x_2, ..., x_n$ são as variáveis de entrada.

O método de mínimos quadrados busca minimizar a soma dos quadrados dos resíduos, ou seja, a diferença entre os valores
observados e os valores previstos pelo modelo. Matematicamente, isso é representado pela equação \ref{eq:minimos_quadrados},
\begin{equation}
\label{eq:minimos_quadrados}
\min_{\beta} \sum_{i=1}^{m} \left(y_i - (\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + ... + \beta_n x_{in})\right)^2
\end{equation}
em que $m$ é o número de observações, $y_i$ é o valor observado da variável de interesse para a $i$-ésima observação,
$x_{ij}$ é o valor da $j$-ésima variável de entrada para a $i$-ésima observação e $\beta$ é o vetor de coeficientes
do modelo.

Ainda que se espere que as relações entre os dados seja altamente não linear, o método é capaz de capturar algumas
das relações lineares entre as variáveis, além de servir como ponto de partida para as próximas análises.


% ----------------------------------------------------------------------------------------------------------------------
\subsection{Modelo Não-linear}
O modelo de regressão não linear utilizado foi o \textit{RandomForestRegressor} da biblioteca \textit{scikit-learn}. O modelo 
funciona a partir de árvores de decisão construídas a partir dos dados de entrada. Cada árvore é treinada em um \textit{subset}
aleatório dos dados e então a árvore cresce por meio da bifurcação. A estrutura do modelo é ilustrada na Figura
\ref{fig:modelo_random_forest}.

\begin{figure}[!ht]
	\IBGEtab{\caption{Modelo com 2 árvores de decisão}
			 \label{fig:modelo_random_forest}}
	{\includesvg[scale=1]{figuras/randomforest}}
	{\fonte{o autor.}}
\end{figure}
Durante a bifurcação, o modelo estabelece o melhor caminho através da combinação de subconjuntos das variáveis de entrada, 
de forma a minimizar o erro na previsão da variável de interesse. A previsão final é obtida através da média das previsões 
de todas as árvores, o que ajuda a reduzir o \textit{overfitting} e melhora a generalização do modelo. A saída do modelo
é dada por:
\begin{equation}
\label{eq:regressao_random_forest}
\hat{y} = \frac{1}{T} \sum_{t=1}^{T} y_t(x)
\end{equation}
em que $T$ é o número de árvores, $y_t(x)$ é a previsão da $t$-ésima árvore e $\hat{y}$ é a previsão final do modelo.


% ----------------------------------------------------------------------------------------------------------------------
\newpage
\section{Modelo Neural}
Antes de apresentar o modelo neural, será feita uma breve introdução a respeito de alguns conceitos importantes,
como o \textit{Perceptron} e os \textit{Multi Layer Perceptrons} (MLPs). Esses conceitos são fundamentais para compreender
a arquitetura do modelo utilizado.

\subsection{O Perceptron}
O \textit{Perceptron} é um modelo de rede neural artificial proposto por \citeonline{Rosenblatt1958}, inspirado no
funcionamento de neurônios biológicos. A figura \ref{fig:perceptron} ilustra a estrutura básica de um Perceptron.

Um perceptron recebe um conjunto $ X = [x_1, x_2, ..., x_n] $ de entradas,
com cada $ x_i $ associada a um peso aleatório $ w_i $. O Perceptron então calcula a soma ponderada das entradas e aplica uma 
função de ativação para produzir a saída. Matematicamente, isso é dado por:
\begin{equation}
\label{eq:perceptron}
\hat{y}(X) = f\left(\sum_{i=1}^{n} w_i x_i + b\right)
\end{equation}
em que $ \hat{y} $ é a saída do Perceptron e $ f $ a função de ativação que, para esse caso, usa-se a função degrau $ u(t) $.

\begin{figure}[!ht]
	\IBGEtab{\caption{Estrutura do Perceptron}
			 \label{fig:perceptron}}
	{\includesvg[scale=1]{figuras/perceptron}}
	{\fonte{o autor.}}
\end{figure}

O Perceptron é limitado a resolver problemas de classificação linearmente separáveis. Ou seja, problemas nos quais é
possível traçar uma linha (ou hiperplano) que separe as classes de forma clara. Para essas aplicações, o Perceptron
atualiza os pesos de modo iterativo durante o treinamento, através da taxa de aprendizado $ r $, conforme a equação 
\ref{eq:atualizacao_perceptron}, que demonstra a atualização dos pesos no tempo:
\begin{equation}
\label{eq:atualizacao_perceptron}
w_i(t+1) \leftarrow w_i(t) + r (y(t) - \hat{y}(t)) x_i
\end{equation}
em que $ y $ é o valor real e $ \hat{y} $ a saída do Perceptron. A taxa de aprendizado representa o quão rápido
os pesos são atualizados durante o treinamento. A atualização é feita de forma a minimizar o erro entre a saída prevista
e a saída real.


% ----------------------------------------------------------------------------------------------------------------------
\subsection{Multi Layer Perceptrons (MLPs)}
MLPs surgiram como uma evolução dos \textit{Perceptrons} simples, com a finalidade de permitir a modelagem de relações
não lineares, e são a base para o \textit{deep learning}, metodologia que utiliza redes neurais com inúmeras camadas para
resolução de tarefas complexas. A figura \ref{fig:mlp_1} ilustra a estrutura básica de um MLP de dupla camada.

\begin{figure}[!ht]
	\IBGEtab{\caption{MLP de dupla camada}
			 \label{fig:mlp_1}}
	{\includesvg[scale=1]{figuras/mlp_1}}
	{\fonte{o autor.}}
\end{figure}

Essas estruturas são compostas por neurônios (perceptrons) interconectados e organizados em camadas. Cada neurônio de uma 
camada está conectado a todos os outros das camadas adjacentes (\textit{fully connected}). A primeira e última camadas são 
chamadas de camada de entrada e camada de saída, respectivamente, enquanto as camadas intermediárias são chamadas de 
camadas ocultas.

MLPs são treinadas utilizando o algoritmo de \textit{backpropagation}, ou retropropagação, que ajusta iterativamente os 
pesos e vieses da rede de forma a minimizar o erro entre a saída prevista e a saída real. O algoritmo funciona em um ciclo 
de quatro etapas, descritas abaixo.

\newpage
\begin{itemize}
\item \textbf{Forward Pass:} os dados de entrada são propagados pelos neurônios até a camada de saída. A saída de cada 
neurônio é calculada em duas fases. Primeiro, a entrada ponderada $ z_i^{(l)} $ para o neurônio $ i $ da camada
$ l $ é a soma das saídas da camada anterior, $ v_j^{(l-1)} $, multiplicadas pelos seus respectivos pesos $ w_{ij}^{(l)} $, 
mais um viés $ b_i^{(l)} $:
\begin{equation}
\label{eq:soma_ponderada_u}
z_i^{(l)} = \sum_{j} (w_{ij}^{(l)} v_j^{(l-1)}) + b_i^{(l)}
\end{equation}
Em seguida, a saída ativada $ v_i^{(l)} $ é obtida aplicando-se a função de ativação $ \sigma $:
\begin{equation}
\label{eq:ativacao_v}
v_i^{(l)} = \sigma(z_i^{(l)})
\end{equation}

\item \textbf{Cálculo do Erro:} uma função de perda $ E $ é usada para quantificar o erro entre a saída $ \hat{y} $ da 
rede e o valor real $ y $. Para tarefas de regressão, costuma-se usar o Erro Quadrático Médio (MSE):
\begin{equation}
\label{eq:mse_v}
E = \frac{1}{n} \sum_{i=1}^{n} (y_{i} - \hat{y}_i)^2
\end{equation}
em que $ n $ é o número de neurônios na camada de saída.

\item \textbf{Backward Pass:} o erro $ E $ é propagado de volta pela rede até a primeira camada. Para isso, a regra da cadeia 
é utilizada para determinar o gradiente da função de perda em relação a cada peso e viés da rede. Para a camada $ L $ de saída, 
o erro $ \delta_i^{(L)} $ é calculado diretamente para cada neurônio $ i $:
\begin{equation}
\label{eq:erro_saida_v}
\delta_i^{(L)} = \frac{\partial E}{\partial v_i^{(L)}} \cdot \sigma'(z_i^{(L)})
\end{equation}
em que $\frac{\partial E}{\partial v_i^{(L)}}$ é a derivada da perda em relação à saída do neurônio $i$ e $\sigma'$ é a 
derivada da função de ativação. Caso seja utilizado o MSE e sabendo que $ v_i^{(L)} = \hat{y_i} $, a equação 
\ref{eq:erro_saida_v} torna-se:
\begin{equation}
\label{eq:erro_saida_mse_v}
\delta_i^{(L)} = (\hat{y}_i - y_i) \cdot \sigma'(z_i^{(L)})
\end{equation}

Para as camadas ocultas, o erro $ \delta_i^{(l)} $ para um neurônio $ i $ na camada $ l $ é calculado recursivamente, 
com base nos erros da camada $ l+1 $ seguinte:
\begin{equation}
\label{eq:erro_oculta_v}
\delta_i^{(l)} = \left( \sum_{j} \delta_j^{(l+1)} w_{ji}^{(l+1)} \right) \cdot \sigma'(z_i^{(l)})
\end{equation}
em que a soma percorre todos os neurônios $j$ da camada seguinte, ponderando seus erros $\delta_j^{(l+1)}$ pelos 
pesos $w_{ji}^{(l+1)}$ que os conectam ao neurônio $i$ da camada atual.

Com o termo $\delta_i^{(l)}$ para cada neurônio, os gradientes dos pesos e vieses são encontrados:
\begin{equation}
\label{eq:gradiente_pesos_v}
\frac{\partial E}{\partial w_{ij}^{(l)}} = \delta_i^{(l)} v_j^{(l-1)}
\end{equation}
\begin{equation}
\label{eq:gradiente_bias_v}
\frac{\partial E}{\partial b_i^{(l)}} = \delta_i^{(l)}
\end{equation}
em que $v_j^{(l-1)}$ é a saída do neurônio $j$ da camada anterior $l-1$.

% \newpage
\item \textbf{Atualização dos Pesos:} finalmente, cada peso e viés da rede é atualizado na direção oposta à do seu gradiente, 
de modo a reduzir o erro na próxima iteração:
\begin{equation}
\label{eq:atualizacao_mlp_v}
w_{ij}^{(l)}(t+1) \leftarrow w_{ij}^{(l)}(t) - r \frac{\partial E}{\partial w_{ij}^{(l)}}
\end{equation}
\begin{equation}
\label{eq:atualizacao_bias_v}
b_i^{(l)}(t+1) \leftarrow b_i^{(l)}(t) - r \frac{\partial E}{\partial b_i^{(l)}}
\end{equation}
em que $t$ representa a iteração atual e $r$ é a taxa de aprendizado, que controla a magnitude da atualização.
\end{itemize}

Em resumo, o processo de aprendizado de um MLP envolve a propagação dos dados de entrada pela rede, o cálculo do erro entre 
a saída prevista e a real, a retropropagação do erro para calcular os gradientes e a atualização dos pesos e vieses para 
minimizar o erro. Esse processo é repetido até que a rede atinja um nível satisfatório de desempenho ou até que um critério
de parada seja atingido, como um número máximo de iterações ou uma tolerância de erro.	


% ----------------------------------------------------------------------------------------------------------------------
\subsection{Arquitetura TSMixer}
A arquitetura proposta por \citeonline{Chen2023} é uma abordagem inovadora para previsão de séries temporais. Ela utiliza
MLPs em cascata, denominadas de \textit{Mixing Layers}, para capturar as relações na dimensão temporal, bem como na dimensão das 
características (variáveis).

A mistura no domínio do tempo permite ao modelo capturar os padrões temporais da série. Essa abordagem se mostrou 
eficaz para aprender padrões temporais como sazonalidades e tendências, sem a necessidade de mecanismos de atenção, 
como os utilizados na arquitetura \textit{Transformer}.

A mistura no domínio das características permite ao modelo capturar as relações entre as variáveis em cada instante de tempo.
Ou seja, o modelo é capaz de aprender como as variáveis interagem entre si ao longo da série temporal. Essa abordagem é 
eficaz para capturar correlações e dependências, sem a necessidade de mecanismos de atenção.

A arquitetura emprega as técnicas de \textit{dropout} e resíduo durante o treinamento. O objetivo é evitar \textit{overfitting}
e melhorar a generalização do modelo. A cada passo de treinamento (época), o \textit{dropout} desliga aleatoriamente um
número de neurônios em uma camada. Dessa forma, a rede é "forçada" a não depender de um conjunto pequeno de neurônios,
fazendo com que o aprendizado seja distribuído entre entre os demais neurônios da camada. Essa abordagem diminui a chance
do modelo apenas memorizar os dados de treinamento (\textit{overfitting}).

A técnica de resíduo é usada para permitir que a entrada de uma camada seja somada à sua saída. O objetivo é manter o
processo de aprendizado eficiente, evitando o efeito de \textit{vanishing gradient}, no qual o gradiente do erro se torna
muito pequeno ao ser propagado às camadas iniciais pelo algoritmo de \textit{backpropagation}.

\begin{figure}[!h]
	\IBGEtab{\caption{Arquitetura do modelo neural usado}
			 \label{fig:arquitetura_modelo_neural}}
	{\includesvg[scale=1]{figuras/tsmixer_1}}
	{\fonte{o autor (adaptado de \citeonline{Chen2023}).}}
\end{figure}

A figura \ref{fig:arquitetura_modelo_neural} ilustra a arquitetura do modelo. As colunas das entradas representam diferentes
variáveis e as linhas são os instantes de tempo. As operações de mistura são realizadas linha a linha. 

As MLPs no domínio do tempo tem seus pesos compartilhados entre todas a todas as variáveis, enquanto as MLPs no domínio das 
características tem seus pesos compartilhados entre todos os instantes de tempo. Para a projeção final, uma camada totalmente 
conectada é usada para mapear o tamanho da entrada (contexto) para o tamanho da saída (previsão). As etapas estão descritas a seguir:

\begin{itemize}
	\item \textbf{Mixing Temporal}: modela padrões temporais da série. Constitui uma única camada de neurônios totalmente
conectada (MLP de camada única), seguida de uma função de ativação e \textit{dropout}. A entrada é transposta para aplicar 
as conexões no domínio do tempo, ou seja, as entradas $ X_i = [x_i(t_1), x_i(t_2), \dots x_i(t_n)] $ são cada variável em todos 
os instantes de tempo, permitindo que o modelo capture os padrões temporais de cada variável utilizando os mesmos pesos.
A saída é transposta novamente para manter a forma original da entrada.

	\item \textbf{Mixing de Características}: modela relações entre as variáveis em cada instante de tempo. Constitui
duas camadas totalmente conectadas (MLPs de camada dupla), também com uma função de ativação e \textit{dropout}. As conexões
são aplicadas no domínio das características, ou seja, as entradas $ T_i = [t_i(x_1), t_i(x_2), \dots t_i(x_n)] $ são
todas as variáveis em um instante de tempo, permitindo ao modelo capturar as relações entre elas, também utilizando os
mesmos pesos.

	\item \textbf{Projeção Temporal}: projetam a saída, mapeando o tamanho da janela de entrada (contexto) para o tamanho 
da janela de saída (previsão). Constitui uma camada totalmente conectada aplicada no domínio do tempo.
\end{itemize}

\citeonline{Chen2023} também propõem uma variante para uso de variáveis exógenas, que são variáveis auxiliares que podem
explicar o comportamento da variável de interesse. No contexto deste projeto, as variáveis exógenas são os dados referentes
ao fenômeno ENSO, como os índices de TSM. Considerando que essa variante ainda não foi disponibilizada publicamente,
para esse projeto foi utilizada uma implementação da arquitetura TSMixer com suporte a variáveis exógenas,
disponibilizada por \citeonline{Ekambaram2024}, denominada de \textit{Tiny Time Mixer}.